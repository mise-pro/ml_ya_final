{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T12:29:14.553005Z",
     "start_time": "2018-09-25T12:29:12.331519Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.externals import joblib\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T12:29:17.457993Z",
     "start_time": "2018-09-25T12:29:14.555002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57315"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = joblib.load('DUMP_data.pkl')\n",
    "len(reviews)\n",
    "#data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T12:29:23.012594Z",
     "start_time": "2018-09-25T12:29:22.752419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews parsed: 57315\n",
      "Total reviews after deduplication: 54971\n"
     ]
    }
   ],
   "source": [
    "print ('Total reviews parsed: {}'.format(len(reviews)))\n",
    "reviews = list(set(reviews))\n",
    "print ('Total reviews after deduplication: {}'.format(len(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reviews and label + delete error of parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T10:03:44.806708Z",
     "start_time": "2018-08-31T10:03:44.423452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews after delete parsing errors: 54486\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "reviews_ = []\n",
    "\n",
    "for idx in range (0,len(reviews)):\n",
    "    if reviews[idx][5]==0:\n",
    "        labels.append(reviews[idx][1])\n",
    "        reviews_.append(str(reviews[idx][2])+str(reviews[idx][3])+str(reviews[idx][4]))\n",
    "print ('Total reviews after delete parsing errors: {}'.format(len(reviews_)))\n",
    "reviews = reviews_[:]\n",
    "#labels\n",
    "#review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T14:23:02.855886Z",
     "start_time": "2018-08-29T14:23:02.636738Z"
    }
   },
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T10:42:02.197576Z",
     "start_time": "2018-08-31T10:03:49.920702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54486 reviews to be normalized...\n",
      "There are 52486 reviews to be normalized...\n",
      "There are 50486 reviews to be normalized...\n",
      "There are 48486 reviews to be normalized...\n",
      "There are 46486 reviews to be normalized...\n",
      "There are 44486 reviews to be normalized...\n",
      "There are 42486 reviews to be normalized...\n",
      "There are 40486 reviews to be normalized...\n",
      "There are 38486 reviews to be normalized...\n",
      "There are 36486 reviews to be normalized...\n",
      "There are 34486 reviews to be normalized...\n",
      "There are 32486 reviews to be normalized...\n",
      "There are 30486 reviews to be normalized...\n",
      "There are 28486 reviews to be normalized...\n",
      "There are 26486 reviews to be normalized...\n",
      "There are 24486 reviews to be normalized...\n",
      "There are 22486 reviews to be normalized...\n",
      "There are 20486 reviews to be normalized...\n",
      "There are 18486 reviews to be normalized...\n",
      "There are 16486 reviews to be normalized...\n",
      "There are 14486 reviews to be normalized...\n",
      "There are 12486 reviews to be normalized...\n",
      "There are 10486 reviews to be normalized...\n",
      "There are 8486 reviews to be normalized...\n",
      "There are 6486 reviews to be normalized...\n",
      "There are 4486 reviews to be normalized...\n",
      "There are 2486 reviews to be normalized...\n",
      "There are 486 reviews to be normalized...\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def normalize_string2(txt):\n",
    "    new_text=''\n",
    "    txt = re.sub('[^\\'а-яА-Я]',' ',txt)\n",
    "    txt = txt.lower()\n",
    "    grams_exclusion = {'PREP','CONJ','PRCL','INTJ','Name','Surn','Patr','Orgn','Trad'}\n",
    "    words = txt.split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if not any (tag in p.tag for tag in grams_exclusion) and (len(p) > 2 or lemma=='не'):\n",
    "            new_text += ' ' + p.normal_form\n",
    "    new_text = new_text [1:]\n",
    "    return new_text\n",
    "\n",
    "\n",
    "#reviewNormalized = [fu.normalize_string2(i) for i in reviews[:20]] #no prints, that's why using prints\n",
    "reviewNormalized = []\n",
    "for review in reviews:\n",
    "    reviewNormalized.append(normalize_string2(review))\n",
    "    if reviews.index(review) % 2000 == 0:\n",
    "        print ('There are {} reviews to be normalized...'.format(len(reviews) - reviews.index(review)))\n",
    "print ('DONE!')\n",
    "#executed in 38m 12s, finished 13:42:02 2018-08-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all to dump files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T10:42:23.635240Z",
     "start_time": "2018-08-31T10:42:02.199579Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = joblib.dump(reviewNormalized, 'DUMP_reviews_normalized.pkl', compress=9)\n",
    "_ = joblib.dump(labels, 'DUMP_labels_normalized.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T21:54:58.529329Z",
     "start_time": "2018-09-07T21:54:57.306410Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = joblib.load('DUMP_reviews_normalized.pkl')\n",
    "d2 = joblib.load('DUMP_labels_normalized.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
