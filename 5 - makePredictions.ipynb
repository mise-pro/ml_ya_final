{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this part only for take part in competition ->\n",
    "https://www.kaggle.com/c/product-reviews-sentiment-analysis/leaderboard\n",
    "\n",
    "use founded earlier params to make prediction + get pkl files for next demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T23:27:31.266518Z",
     "start_time": "2018-09-01T23:27:17.814507Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import functions as fu\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import ensemble\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T23:27:31.284525Z",
     "start_time": "2018-09-01T23:27:31.268515Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_file (predictions, filename):\n",
    "    predictionsMapping = [('Id', [i for i in range (0,100)]),\n",
    "                          ('y', ['pos' if prediction==1 else 'neg' for prediction in predictions])]\n",
    "    answers = pd.DataFrame.from_items(predictionsMapping)\n",
    "    answers.to_csv(filename, sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T23:27:32.328303Z",
     "start_time": "2018-09-01T23:27:31.286528Z"
    }
   },
   "outputs": [],
   "source": [
    "dataTrain = joblib.load('DUMP_reviews_normalized.pkl')\n",
    "labels = joblib.load('DUMP_labels_normalized.pkl')\n",
    "dataTest = joblib.load('DUMP_data_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T23:27:43.963900Z",
     "start_time": "2018-09-01T23:27:32.330834Z"
    }
   },
   "outputs": [],
   "source": [
    "dataTrainNormalized = dataTrain\n",
    "dataTestNormalized = [fu.normalize_string2(i) for i in dataTest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T23:27:43.992488Z",
     "start_time": "2018-09-01T23:27:43.965901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make decision: tranfer 1-5 rating to 0-1 rating\n",
    "labels_=[]\n",
    "for idx in range (0, len(labels)):\n",
    "    labels_.append(1 if labels[idx]>3 else 0)\n",
    "labels = labels_\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T21:37:45.679438Z",
     "start_time": "2018-08-25T21:37:45.383688Z"
    }
   },
   "source": [
    "## Model  - svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T13:29:25.618189Z",
     "start_time": "2018-09-25T13:29:25.454079Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearSVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b5314d806156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcurrentVectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataTrainNormalizedVect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrentVectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTrainNormalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearSVC' is not defined"
     ]
    }
   ],
   "source": [
    "clf2 = LinearSVC()\n",
    "\n",
    "currentVectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "dataTrainNormalizedVect = currentVectorizer.fit_transform(dataTrainNormalized)\n",
    "\n",
    "model2 = clf2.fit(dataTrainNormalizedVect, labels)\n",
    "\n",
    "dataTestNormalizedVect = currentVectorizer.transform(dataTestNormalized)\n",
    "\n",
    "predictions2 = model2.predict (dataTestNormalizedVect)\n",
    "predictions2\n",
    "to_file(predictions2, 'answers2.csv')\n",
    "# kaggle 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'data/model.pkl'\n",
    "_ = joblib.dump(model2, filename, compress=9)\n",
    "filename = 'data/vectorizer.pkl'\n",
    "_ = joblib.dump(currentVectorizer, filename, compress=9)\n",
    "\n",
    "#copy these files to flask\n",
    "#data/model.pkl + data/vectorizer.pkl - about 150Mb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
